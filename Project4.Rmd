---
title: "Project 4: Bank Marketing"
output:
  pdf_document:
    number_sections: TRUE
  html_document:
    number_sections: TRUE
date: "02/28/2020"
---
<style type="text/css">

body{ /* Normal  */
      font-size: 18px;
  }
</style>
```{r setup, include=FALSE}
library(knitr)

opts_chunk$set(size='small'
               , cache=TRUE
               , cache.path='cache/'
               , comment=NA
               , warning=FALSE
               , message=FALSE
               , fig.align='center'
               , dpi=100
               , fig.path='figure/'
               , fig.pos='H'
               , background='#ffffff'
               , results='hold'
               , fig.show='hold'
               , echo=FALSE)
```
```{r}
library(MASS)
library(dplyr)
library(e1071)
library(klaR)
library(FNN)
library(randomForest)
library(rpart)
library(partykit)
library(pROC)
library(latticeExtra)
library(caret)
library(broom)
```
# Introduction
## Background

Marketing selling campaigns constitute a typical strategy to enhance business. Companies use direct marketing when targeting segments of customers by contacting them to meet a specific goal. Telephone (fixed-line or mobile) is one of the most widely used. Technology enables rethinking marketing by focusing on maximizing customer lifetime value through the evaluation of available information and customer metrics, thus allowing us to build longer and tighter relations in alignment with business demand [1].

The dataset is downloaded from UCI Machine Learning Repository and is related to direct marketing campaigns of a Portuguese Banking institution [2]. These campaigns were based on phone calls. Often, more than one calls were done to the same client to access if their product “term deposit” will be subscribed (yes) or not subscribed (no). There were 4 datasets in it from which bank-additional-full.csv is used that has all examples (41188) and 20 inputs ordered by date (from May 2008 to November 2010). There are 20 input variables and 1 output variable (desired target).  These dataset attributes denote customer data, socio-economic data, telemarketing data and some other data. Some attributes are numerical, and some are categorical. The dataset was loaded in R Studio and checked for any missing values using is.na function and found that it didn’t have any missing values, so we have a clean dataset. 

## Statistical questions of interest

Our main goal is to build prediction models based on the data set to predict response variables, which a customer would subscribe bank long-term deposit or not. Based on all 20 variables from the data set, we need to select the variables by stepwise method to build models. After that, we divide the data into training data and test data. We will fit two models through training data, including logistics regression model and random forest, respectively. Then, we will test the models on test data. Our interest in this project is to calculate the prediction accuracy of these two models and compare the gap performance of the two models. 

# Analysis Plan


## Descriptive Analysis

**Table.1 Features description of the Bank Marketing Dataset (BMD).**  

| Feature | Description | Attribution |
|------|----------------------|-----|
|`y`| Desired target. Has the client subscribed a term deposit?   | binary |  
|`age`|  Client Age | numeric |
|`job`|  Type of Job | categorical |  
|`marital `|  Client’s marital status | categorical |  
|`education`|  Client’s education | categorical |  
|`default`| Has credit in default? | categorical |
|`housing`| Has housing loan? | categorical |
|`loan`| Has personal loan? | categorical |
|`contact`| Last contact month of year | categorical |
|`month`| Month of last contact with client | categorical |
|`day_of_week`| Last contact day of the week | categorical |
|`duration`| last contact duration, in seconds |  numeric |
|`campaign`| Number of contacts performed during this campaign and for this client | categorical |
|`pdays`| Number of days that passed by after the client was last contacted from a previous campaign | numeric |
|`previous`| Number of client contacts performed before this campaign | numeric |
|`poutcome`| Outcome of the previous marketing campaign | categorical |
|`emp.var.rate`| Quarterly employment variation rate | numeric |
|`cons.price.idx`| Monthly consumer price index | numeric |
|`cons.conf.idx`| Monthly consumer confidence index | numeric |
|`euribor3m`| Daily euribor 3-month rate | numeric |
|`nr.employed`| Quarterly number of employees | numeric |
 
By description, `duration` should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model. So this attribute highly affects the output target. More than 95% values in `pdays` are 999, which means client was not previously contacted. Only 3 cases are `yes` in `default`, and more than 20% are unknown. So we remove these three variables. 

## Predictive Model

To predict, given the seventeen features, if the bank term deposit would be or
not subscribed, we used logistic regression and random forest. As mentioned before, the BMD consists of 41188 observations. A random sample of 10% of this size, 4119 observations, was withdrawn to be used as a test dataset. The rest, 37069 observations, was used as a train dataset.

### Logistic Regression

The main goal of our project is to predict whether the client has subscribed a term deposit. In other words, the response variable has a binary outcome. Therefore, we decide to choose the logistic model to fit the dataset. The model is given as follows:

$${\displaystyle \log{\frac{p}{1-p}}=\beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+\cdots +\beta_{n}x_{n}}$$

where $p(x)$ is the probability that the dependent variable equals a case, given some linear combination of the predictors; $x_i, i=1,\cdots,n$ is the predict variables; $\beta_{0}$ is the intercept from the linear regression equation and $\beta_i, i=1,\cdots,n$ is the regression coefficient.

- The outcome is a binary or dichotomous variable like yes vs no, positive vs negative, 1 vs 0.

- There is no influential values (extreme values or outliers) in the continuous predictors.

- There is no high intercorrelations (i.e. multicollinearity) among the predictors.

To test the significance of the features we use the Akaike information criterion
(AIC). Given a collection of models, the AIC estimates the quality of each model,
relative to each of the other models. Thus, AIC provides a means for model 
selection.

## Model Diagnostic

According to the assumptions of the logistic model, we will first check if the outcome is binary. Influential values are extreme individual data points that can alter the quality of the logistic regression model. So, Cook's Distance plot and Studentized Residual plot will be figured to find whether there are influential values and outliers in the dataset. Finally, Multicollinearity will be considered by VIF values becuase it corresponds to a situation where the data contain highly correlated predictor variables.

### Random Forest

Random forests are an ensemble learning method that operate by constructing a
multitude of decision trees at training time and outputting the class that is the
mode of the classes (classification) or mean prediction (regression) of the
individual trees. Random decision forests correct for decision trees' habit of
overfitting to their training set.

Random forests differ in only one way from tree bagging: they use a modified tree
learning algorithm that selects, at each candidate split in the learning process,
a random subset of the features. Tree bagging repeatedly selects a random sample
with replacement of the training set and fits trees to these samples. This
bootstrapping procedure leads to better model performance because it decreases the
variance of the model, without increasing the bias. More details about can be see,
for example, in https://en.wikipedia.org/wiki/Random_forest.

In R, the main implementation of random forest is found in the
randomForest library [randomForest].

## Comparison

The main measure that can be used to compare different algorithms is the
Receiver Operating Characteristic curve, i.e. ROC curve. A graphical plot that
illustrates the diagnostic ability of a binary classifier system as its
discrimination threshold is varied. The ROC curve is created by plotting the 
specificity, true negative rate, against the sensitivity, true positive rate, at
various threshold settings. In R, the main implementation of the ROC curve is found in the pROC library [pROC].

When dealing with ROC curves the main measure returned is the Area Under the Curve
(AUC), that is qual to the probability that a classifier will rank a randomly
chosen positive instance higher than a randomly chosen negative one. 


# Results 

## Descriptive Analysis

```{r}
library(data.table)
temp <- tempfile()
download.file('https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip', temp)
data  <- read.table(unzip(zipfile = temp, 
                                     files = 'bank-additional/bank-additional-full.csv', 
                                     junkpaths = TRUE), header = TRUE, sep = ';')
#Using Local Dataset location
#data <- read.csv(file="./bank-additional-full.csv", header=TRUE, sep=";")
```
```{r, results='hide'}
#summary of data
dim(data)
names(data)

#summary before cleaning
str(data)
summary(data)

# Check for any missing values:
sum(is.na(data))

sum(data$default=="unknown")/dim(data)[1]
```

```{r}
data <- data[ , -c(5, 11, 13)]
```


```{r}
quant <- data[ , c(1, 10, 11, 13:17)]
pairs(quant
      , upper.panel = function(x, y, ...) {
        usr <- par("usr") ; on.exit(par(usr)) ; par(usr = c(0, 1, 0, 1))
        r <- cor(x, y)
        txt <- format(c(r, 0.123456789), digits = 2)[1]
        text(.5, .5, txt, cex = 1.25)
      }
      , diag.panel = function(a, b, ...) {
        usr <- par("usr") ; on.exit(par(usr)) ; par(usr = c(0, 1, 0, 1))
        rect(0, 0, 1, 1, col = "#37B9DA")
      }
      , pch = 19, gap = .25, xaxt = "n", yaxt = "n"
      , col = c("#0080FF", "#F3953E")[data$y]
      , label.pos = .5, oma = c(1, 1, 1, 1))
```


**Figure.1 Scatterplot lower triangular matrix and correlation upper triangular matrix for all the quantitative features presented in the Bank Marketing Dataset (BMD).**

In Figure 1 we see the scatterplots and correlations, two-by-two,
for all the eight numerical features in the BMD. In more than half of them we see
a random behaviour, that is also described by a correlation close to zero or
between the interval -0.3 and 0.3. A (very) strong (and positive) correlation is
seen in three cases. `emp.var.rate` vs. `euribor3m` (cor. 0.97),
`euribor3m` vs. `nr.employed` (cor. 0.95), and
`emp.var.rate` vs. `nr.employed` (cor. 0.91), i.e., involving only
three features - employment variation rate, Euro Interbank Offered Rate (Euribor)
and number of employees. To avoid high collinearlity, we only remain `nr.employed` to analysis.
```{r}
data <- data[,-c(16,19)]
```
```{r,fig.width=9, fig.height=8}
barras <- function(variable, nome, limite) {
  da = table(variable)
  barchart(sort(da)
           , col = "orange"
           , border = "transparent"
           , xlab = NULL
           , main = nome
           , scales = list(x = list(draw = FALSE))
           , xlim = limite
           , panel = function(...){
             panel.barchart(...)
             args <- list(...)
             panel.text(args$x, args$y, args$x, pos = 4, cex = .8)})
}
print(barras(data$job, "job", c(0, 15e3)),
      position = c(0, 3/4, 1/3, 1), more = TRUE)
print(barras(data$marital, "marital", c(0, 33e3)),
      position = c(1/3, 3/4, 2/3, 1), more = TRUE)
print(barras(data$education, "education", c(0, 19e3)),
      position = c(2/3, 3/4, 1, 1), more = TRUE)
print(barras(data$housing, "housing", c(0, 28e3)),
      position = c(0, 2/4, 1/3, 3/4), more = TRUE)
print(barras(data$loan, "loan", c(0, 44e3)),
      position = c(1/3, 2/4, 2/3, 3/4), more = TRUE)
print(barras(data$contact, "contact", c(0, 35e3)),
      position = c(2/3, 2/4, 1, 3/4), more = TRUE)
print(barras(data$month, "month", c(0, 18e3)),
      position = c(0, 1/4, 1/3, 2/4), more = TRUE)
print(barras(data$day_of_week, "day_of_week", c(0, 11e3)),
      position = c(1/3, 1/4, 2/3, 2/4), more = TRUE)
print(barras(data$poutcome, "poutcome", c(0, 47e3)),
      position = c(2/3, 1/4, 1, 2/4), more = TRUE)
print(barras(data$y, "y", c(0, 46e3)),
      position = c(1/3, 0, 2/3, 1/4))
```

**Figure.2 Bar plots for all the qualitative features presented in the Bank Marketing Dataset (BMD).**

Already in Figure 2 we have the frequencies for each level of the
categorical features in the BMD. First, we see that the desired target is 
unbalanced, with more than 85% of the observations corresponding to clients that
didn't subscribed to a term deposit. An equilibrium between levels is only present
in the `day.of.week` last contact feature. By this Figure we can also see
that the last contact of most of the clients was in may (`month` feature),
that most of the clients have a nonexistent previous marketing campaign
(`poutcome` feature), that they are married (`marital` feature) and
that most have a `job` in the administrative sector.


## Logistic Regression

```{r}
set.seed(0228)
#choose 10% as test data
id <- sample(1:nrow(data), round(nrow(data) / 10, 0))

train <- data[-id, ] ; test <- data[id, ]
```

```{r, cache = TRUE, results='hide'}
logist <- glm(y ~ ., family = binomial, train) ; logist <- stepAIC(logist)
```
```{r, results='hide'}
summary(logist)
```

From fifteen features, logistic regression model finished with nine: `job`, `contact`, `month`, `day_of_week`, `campaign`, `poutcome`, `emp.var.rate`, `cons.price.idx`, `cons.conf.idx` and `nr.employed`. Keeping a variable means that the feature was statistically significant, in describing the difference between the classes of the desired target - if the bank term deposit would be or not subscribed.

```{r, results='hide'}
logist.pred<-predict(logist,test,"response")
logist.pred<-as.factor(ifelse(logist.pred<=0.5, "no", "yes"))
# Confusion matrix
confusionMatrix(logist.pred, test$y)
```

## Model Diagnostics


### Binary outcome

Our desired target `y` means that whether the client has subscribed a term deposit or not. Therefore, the outcome satisfies the binary outcome assumption.  

### Influential values

Influential values are extreme individual data points that can alter the quality of the logistic regression model. The Cook's distances are much smaller than 1, meaning that there is not influential case in the dataset. To check whether the data contains potential outliers, the standardized residual error can be inspected. If an observation has an externally studentized residual that is larger than 3 (in absolute value), we can call it an outlier. Therefore, from the plot, we can verify that there is none outliers in the dataset [olsrr].

```{r}
par(mfrow=c(1,2))
plot(logist, which = 4, id.n = 15)
model.data <- augment(logist) %>% 
  mutate(index = 1:n())
plot(model.data$.fitted, model.data$.std.resid, xlab = 'fitted value', ylab = 'studentized residual', main = 'Studentized residuals vs fitted values')
par(mfrow=c(1,1))
```
**Figure.3 **

### Multicollinearity

Multicollinearity is an important issue in regression analysis and should be fixed by removing the concerned variables. As a rule of thumb, a VIF value that exceeds 10 indicates a problematic amount of collinearity. In our model, only the variable `emp.var.rate` has a VIF value larger than 10, indicating a problem of collinearity.

```{r, results='hide'}
car::vif(logist)
```
**Table.2 **

|   Fit   | job  |  contact  |  month  |  day_of_week | campaign | poutcome | emp.var.rate | cons.price.idx | cons.conf.idx | nr.employed |
|------|------|-----------|---------| -------------|----------|----------|--------------|----------------|---------------|-------------|
| VIF | 1.01  | 1.54 | 1.20 | 1.01  | 1.02 | 1.07 | 11.99 | 7.31 | 1.61 | 8.67 |


## Comparison between Logistic Regression and Random Forest

```{r, cache=TRUE}
bag <- randomForest(x = train[, -17], y = train[ , 17], importance = FALSE)
```

```{r, results='hide'}
bag.pred<-predict(bag, test)
# Confusion matrix
confusionMatrix(bag.pred, test$y)
```

**Table.3 Confusion table between prediction and true value in logistic regression and rondom forest**

| logistic regression | |  True | True | | random forest | |  True | True |
|-----|--|--|--|----|----|--|--|--|
|     | | no | yes | | | | no | yes |
| Predicted  |no | 3628 | 321| |  Predicted  |no | 3573 | 286 |
| Predicted  |yes| 71 | 99| | Predicted  |yes| 126 | 134 |


Table 3 is about the confusion table between fited value and true bvalue in logistic regression and rondom forest. The AUC for each model is presented in Figure 4. The highest is obtained with the logistic regression model. Table 5 shows some measures that include specificity, sensitivity, and accuracy in different models. The logistic regression model has a higher sensitivity and accuracy, and the random forest model has a higher specificity. Both of them have a good sensitivity, true positive rate, but a bad specificity, true negative rate, which means that these classifiers rarely overlook people who will subscribe to a term deposit. Still, they are more likely to consider people who have no intention to subscribe to a term deposit are prone to subscribe to it in the future. From the above, it shows that the logistic regression model has a better performance compared to the random forest model.

```{r,,fig.width=8, fig.height=3}
par(mfrow = c(1, 2))
# ---------------------------------------------------------- logistic regression #
plot.roc(roc(test$y, predict(logist, test, type = "response"))
         , main = "Logistic"
         #, print.thres = TRUE
         , print.auc = TRUE, print.auc.cex = 1.25, print.auc.adj = c(.5, 3)
         , auc.polygon = TRUE, max.auc.polygon = TRUE)


# ------------------------------------------------------------ --- random forest #
plot.roc(roc(test$y, as.numeric(predict(bag, test)))
         , main = "Random forest"
         #, print.thres = TRUE
         , print.auc = TRUE, print.auc.cex = 1.25, print.auc.adj = c(.5, 3)
         , auc.polygon = TRUE, max.auc.polygon = TRUE)

```
**Figure.4 ROC curve for each model (in the test) with respective AUC and thresholds.**

**Table.5  Specificity, sensitivity and accuracy for each model in the test Bank Marketing Dataset.**  

| Model | Specificity | Sensitivity | Accuracy |
|------|-----------|---------|---------|
|Logistic regression|  0.2357    |   **0.9808** |  **0.9048**   |
|Random forest|    **0.3167**   |  0.9654   |   0.8992   |

# Discussion




\pagebreak

# Appendix. Reference

[1] [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014

[2] Bank Marketing Data Set. UCI machine learning repository. https://archive.ics.uci.edu/ml/datasets/Bank+Marketing.

[randomForest] Liaw, A. & Wiener M. (2002). Classification and Regression by randomForest. R News 2(3), 18--22. http://CRAN.R-project.org/doc/Rnews/.

[pROC] Robin, X., Turck, N., Hainard, etc. (2011). pROC: an open-source package for R and S+ to analyze and compare ROC curves. BMC Bioinformatics, 12, p. 77. DOI: 10.1186/1471-2105-12-77. http://www.biomedcentral.com/1471-2105/12/77/.

[olsrr] https://cran.r-project.org/web/packages/olsrr/vignettes/influence_measures.html

# Appendix II. Group Partners

This Document is the project 3 of Team 7 in STA 207, Winter 2020.

1. Bingdao Chen bdchen@ucdavis.edu contribution: descriptive analysis and model establishment

2. Yahui Li yhuli@ucdavis.edu contribution: casual inference and conclusion

3. Zihan Wang zihwang@ucdavis.edu contribution: fixed effects model

4. Jian Shi jnshi@ucdavis.edu contribution: model diagnose

The repository in Github is on https://github.com/yhli097/STA207Project4.git

